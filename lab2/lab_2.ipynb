{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n",
      "[nltk_data] Downloading package wordnet to /home/alex/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from gensim.models import FastText, Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_df = pd.read_csv('data/train.csv')\n",
    "test_raw_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reuters)</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipeline (Reuters)</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new menace to US economy (AFP)</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>1</td>\n",
       "      <td>Pakistan's Musharraf Says Won't Quit as Army Chief</td>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Pervez Musharraf  has said he will stay on as army chief, reneging on a pledge to  quit the powerful post by the end of the year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>2</td>\n",
       "      <td>Renteria signing a top-shelf deal</td>\n",
       "      <td>Red Sox general manager Theo Epstein acknowledged Edgar Renteria was more a luxury for the 2005 Red Sox than a necessity. But there's nothing wrong with getting the keys to a BMW, and that's what the four-time All-Star and two-time Gold Glover is in the eyes of the Red Sox.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>2</td>\n",
       "      <td>Saban not going to Dolphins yet</td>\n",
       "      <td>The Miami Dolphins will put their courtship of LSU coach Nick Saban on hold to comply with the NFL's hiring policy by interviewing at least one minority candidate, a team source told The Associated Press last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>2</td>\n",
       "      <td>Today's NFL games</td>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: Steelers by 10. Records: Steelers 12-1, Giants 5-8. Vs. spread: Steelers 10-1-2, Giants 5-8. Series: Giants lead, 43-27-3. Comments: Think the Giants knew Ben Roethlisberger was available on draft day when they broke the bank and traded for Eli Manning? . . . All Big Ben has done this year is complete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2</td>\n",
       "      <td>Nets get Carter from Raptors</td>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was traded by the Toronto Raptors to the New Jersey Nets for Alonzo Mourning, Eric Williams, Aaron Williams, and a pair of first-round draft picks yesterday.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class Index  \\\n",
       "0       3             \n",
       "1       3             \n",
       "2       3             \n",
       "3       3             \n",
       "4       3             \n",
       "...    ..             \n",
       "119995  1             \n",
       "119996  2             \n",
       "119997  2             \n",
       "119998  2             \n",
       "119999  2             \n",
       "\n",
       "                                                                            Title  \\\n",
       "0       Wall St. Bears Claw Back Into the Black (Reuters)                           \n",
       "1       Carlyle Looks Toward Commercial Aerospace (Reuters)                         \n",
       "2       Oil and Economy Cloud Stocks' Outlook (Reuters)                             \n",
       "3       Iraq Halts Oil Exports from Main Southern Pipeline (Reuters)                \n",
       "4       Oil prices soar to all-time record, posing new menace to US economy (AFP)   \n",
       "...                                                                           ...   \n",
       "119995  Pakistan's Musharraf Says Won't Quit as Army Chief                          \n",
       "119996  Renteria signing a top-shelf deal                                           \n",
       "119997  Saban not going to Dolphins yet                                             \n",
       "119998  Today's NFL games                                                           \n",
       "119999  Nets get Carter from Raptors                                                \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                             Description  \n",
       "0       Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.                                                                                                                                                                                                                                                                    \n",
       "1       Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.                                                                                                                                            \n",
       "2       Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.                                                                                                                                                                          \n",
       "3       Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.                                                                                                                                                               \n",
       "4       AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.                                                                                                                                                                                                  \n",
       "...                                                                                                                                                                  ...                                                                                                                                                                                                  \n",
       "119995   KARACHI (Reuters) - Pakistani President Pervez Musharraf  has said he will stay on as army chief, reneging on a pledge to  quit the powerful post by the end of the year.                                                                                                                                                                                        \n",
       "119996  Red Sox general manager Theo Epstein acknowledged Edgar Renteria was more a luxury for the 2005 Red Sox than a necessity. But there's nothing wrong with getting the keys to a BMW, and that's what the four-time All-Star and two-time Gold Glover is in the eyes of the Red Sox.                                                                                \n",
       "119997  The Miami Dolphins will put their courtship of LSU coach Nick Saban on hold to comply with the NFL's hiring policy by interviewing at least one minority candidate, a team source told The Associated Press last night.                                                                                                                                           \n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: Steelers by 10. Records: Steelers 12-1, Giants 5-8. Vs. spread: Steelers 10-1-2, Giants 5-8. Series: Giants lead, 43-27-3. Comments: Think the Giants knew Ben Roethlisberger was available on draft day when they broke the bank and traded for Eli Manning? . . . All Big Ben has done this year is complete ...  \n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was traded by the Toronto Raptors to the New Jersey Nets for Alonzo Mourning, Eric Williams, Aaron Williams, and a pair of first-round draft picks yesterday.                                                                                                                                                               \n",
       "\n",
       "[120000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "Очевидно, что удаление знаков препинания и других символов необходимо, чтобы избежать кодирования не несущих смысл символов, сделаем это для всех экспериментов. Затем сравним удаление стоп-слов, удаление цифр и их комбирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls count:\n",
      "Class Index    0\n",
      "Title          0\n",
      "Description    0\n",
      "dtype: int64\n",
      "\n",
      "Empty string count:\n",
      "Class Index    0\n",
      "Title          0\n",
      "Description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nulls count:\", train_raw_df.isna().sum(), sep='\\n')\n",
    "print()\n",
    "print(\"Empty string count:\", train_raw_df.eq('').sum(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, remove_digits=False, remove_stop_words=False):\n",
    "    train_df = train_raw_df.copy(deep=True)\n",
    "\n",
    "    train_df['text'] = train_raw_df['Title'] + \" \" + train_raw_df['Description']\n",
    "    train_df.drop(columns=['Title', 'Description'], inplace=True)\n",
    "\n",
    "    train_df['text'] = train_df['text'].str.replace(\"\\\\\", \" \").str.lower()\n",
    "    \n",
    "    if remove_digits:\n",
    "        train_df['text'] = train_df['text'].str.replace(r'\\d', ' ', regex=True)\n",
    "\n",
    "    if remove_stop_words:\n",
    "        stop_words = stopwords.words('english')\n",
    "        stop_words_pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in stop_words) + r')\\b'\n",
    "        train_df['text'] = train_df['text'].str.replace(stop_words_pattern, ' ', regex=True)\n",
    "\n",
    "    train_df['text'] = train_df['text'].str.replace(r'[^\\d\\w\\s]', '', regex=True)\n",
    "    train_df['text'] = train_df['text'].apply(word_tokenize, preserve_line=True)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_removed_digits = clean_text(train_raw_df, remove_digits=True)\n",
    "train_removed_stopw = clean_text(train_raw_df, remove_stop_words=True)\n",
    "train_removed_all = clean_text(train_raw_df, remove_digits=True, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[wall, st, bears, claw, back, black, reuters, reuters, shortsellers, wall, street, dwindling, band, ultracynics, seeing, green]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[carlyle, looks, toward, commercial, aerospace, reuters, reuters, private, investment, firm, carlyle, group, reputation, making, welltimed, occasionally, controversial, plays, defense, industry, quietly, placed, bets, another, part, market]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[oil, economy, cloud, stocks, outlook, reuters, reuters, soaring, crude, prices, plus, worries, economy, outlook, earnings, expected, hang, stock, market, next, week, depth, summer, doldrums]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[iraq, halts, oil, exports, main, southern, pipeline, reuters, reuters, authorities, halted, oil, export, flows, main, pipeline, southern, iraq, intelligence, showed, rebel, militia, could, strike, infrastructure, oil, official, said, saturday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[oil, prices, soar, time, record, posing, new, menace, us, economy, afp, afp, tearaway, world, oil, prices, toppling, records, straining, wallets, present, new, economic, menace, barely, three, months, us, presidential, elections]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>1</td>\n",
       "      <td>[pakistan, musharraf, says, quit, army, chief, karachi, reuters, pakistani, president, pervez, musharraf, said, stay, army, chief, reneging, pledge, quit, powerful, post, end, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>2</td>\n",
       "      <td>[renteria, signing, topshelf, deal, red, sox, general, manager, theo, epstein, acknowledged, edgar, renteria, luxury, red, sox, necessity, nothing, wrong, getting, keys, bmw, fourtime, star, twotime, gold, glover, eyes, red, sox]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>2</td>\n",
       "      <td>[saban, going, dolphins, yet, miami, dolphins, put, courtship, lsu, coach, nick, saban, hold, comply, nfl, hiring, policy, interviewing, least, one, minority, candidate, team, source, told, associated, press, last, night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>2</td>\n",
       "      <td>[today, nfl, games, pittsburgh, ny, giants, time, p, line, steelers, records, steelers, giants, vs, spread, steelers, giants, series, giants, lead, comments, think, giants, knew, ben, roethlisberger, available, draft, day, broke, bank, traded, eli, manning, big, ben, done, year, complete]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2</td>\n",
       "      <td>[nets, get, carter, raptors, indianapolis, star, vince, carter, traded, toronto, raptors, new, jersey, nets, alonzo, mourning, eric, williams, aaron, williams, pair, firstround, draft, picks, yesterday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class Index  \\\n",
       "0       3             \n",
       "1       3             \n",
       "2       3             \n",
       "3       3             \n",
       "4       3             \n",
       "...    ..             \n",
       "119995  1             \n",
       "119996  2             \n",
       "119997  2             \n",
       "119998  2             \n",
       "119999  2             \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                     text  \n",
       "0       [wall, st, bears, claw, back, black, reuters, reuters, shortsellers, wall, street, dwindling, band, ultracynics, seeing, green]                                                                                                                                                                    \n",
       "1       [carlyle, looks, toward, commercial, aerospace, reuters, reuters, private, investment, firm, carlyle, group, reputation, making, welltimed, occasionally, controversial, plays, defense, industry, quietly, placed, bets, another, part, market]                                                   \n",
       "2       [oil, economy, cloud, stocks, outlook, reuters, reuters, soaring, crude, prices, plus, worries, economy, outlook, earnings, expected, hang, stock, market, next, week, depth, summer, doldrums]                                                                                                    \n",
       "3       [iraq, halts, oil, exports, main, southern, pipeline, reuters, reuters, authorities, halted, oil, export, flows, main, pipeline, southern, iraq, intelligence, showed, rebel, militia, could, strike, infrastructure, oil, official, said, saturday]                                               \n",
       "4       [oil, prices, soar, time, record, posing, new, menace, us, economy, afp, afp, tearaway, world, oil, prices, toppling, records, straining, wallets, present, new, economic, menace, barely, three, months, us, presidential, elections]                                                             \n",
       "...                                                                                                                                                                                                                                        ...                                                             \n",
       "119995  [pakistan, musharraf, says, quit, army, chief, karachi, reuters, pakistani, president, pervez, musharraf, said, stay, army, chief, reneging, pledge, quit, powerful, post, end, year]                                                                                                              \n",
       "119996  [renteria, signing, topshelf, deal, red, sox, general, manager, theo, epstein, acknowledged, edgar, renteria, luxury, red, sox, necessity, nothing, wrong, getting, keys, bmw, fourtime, star, twotime, gold, glover, eyes, red, sox]                                                              \n",
       "119997  [saban, going, dolphins, yet, miami, dolphins, put, courtship, lsu, coach, nick, saban, hold, comply, nfl, hiring, policy, interviewing, least, one, minority, candidate, team, source, told, associated, press, last, night]                                                                      \n",
       "119998  [today, nfl, games, pittsburgh, ny, giants, time, p, line, steelers, records, steelers, giants, vs, spread, steelers, giants, series, giants, lead, comments, think, giants, knew, ben, roethlisberger, available, draft, day, broke, bank, traded, eli, manning, big, ben, done, year, complete]  \n",
       "119999  [nets, get, carter, raptors, indianapolis, star, vince, carter, traded, toronto, raptors, new, jersey, nets, alonzo, mourning, eric, williams, aaron, williams, pair, firstround, draft, picks, yesterday]                                                                                         \n",
       "\n",
       "[120000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls count:\n",
      "\tRemoved digits: 0\n",
      "\tRemoved stop words: 0\n",
      "\tRempved both: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Nulls count:\")\n",
    "print(\"\\tRemoved digits:\", train_removed_digits['text'].isna().sum())\n",
    "print(\"\\tRemoved stop words:\", train_removed_stopw['text'].isna().sum())\n",
    "print(\"\\tRempved both:\", train_removed_all['text'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join(lemmatizer.lemmatize(token) for token in text)\n",
    "\n",
    "def stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return ' '.join(stemmer.stem(token) for token in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    def __init__(self, vect_type, params = None) -> None:\n",
    "        self.vect_type = vect_type\n",
    "        self.params = params\n",
    "    \n",
    "    def _split_text(self, text):\n",
    "        return [sentence.split() for sentence in text]\n",
    "    \n",
    "    def fit(self, text):\n",
    "        if self.vect_type == \"word2vec\":\n",
    "            self.vectorizer = Word2Vec(sentences=self._split_text(text), **self.params)\n",
    "            \n",
    "        elif self.vect_type == \"fasttext\":\n",
    "            self.vectorizer = FastText(sentences=self._split_text(text), **self.params)\n",
    "            \n",
    "        elif self.vect_type == \"tfidf\":\n",
    "            self.vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "            self.vectorizer.fit(text)\n",
    "            \n",
    "    def transform(self, text):\n",
    "        if self.vect_type == \"tfidf\":\n",
    "            return self.vectorizer.transform(text).toarray()\n",
    "        else:\n",
    "            embeddings = []\n",
    "            for sentence in text:\n",
    "                vector = self.vectorizer.wv\n",
    "                null_emb = np.zeros(self.params['vector_size'])\n",
    "                embeddings.append(np.mean([vector[token] if token in vector else null_emb for token in sentence ], axis=0))\n",
    "                \n",
    "            return np.array(embeddings)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(X_train, y_train, X_test):\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cleaning_dict = {\"Removed digits\" : train_removed_digits, \n",
    "#                       \"Removed stop words\" : train_removed_stopw,\n",
    "#                       \"Removed digits and stop words\" : train_removed_all}\n",
    "\n",
    "# tokenizing_type_dict = {\"lemmatizing\" : lemmatizing, \"stemming\" : stemming}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data_cleaning_type, data in data_cleaning_dict.items():\n",
    "    \n",
    "#     X = data[['text']].copy()\n",
    "#     y = data[['Class Index']].copy()\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=31)\n",
    "#     del X, y\n",
    "    \n",
    "#     for tokenizing_type, tokenizing_func in tokenizing_type_dict.items():\n",
    "        \n",
    "#         X_train['text'] = X_train['text'].apply(tokenizing_func)\n",
    "#         X_test['text'] = X_test['text'].apply(tokenizing_func)\n",
    "\n",
    "#         for vectorization_type in [\"tfidf\", \"word2vec\", \"fasttext\"]:\n",
    "#             if vectorization_type == \"tfidf\":\n",
    "#                 params = None\n",
    "#             else:\n",
    "#                 params = {'vector_size': 100,\n",
    "#                         'window': 5,\n",
    "#                         'min_count': 1,\n",
    "#                         'workers': 4\n",
    "#                     }\n",
    "                \n",
    "#             vectorizer = Vectorizer(vectorization_type, params)\n",
    "#             vectorizer.fit(X_train['text'])\n",
    "            \n",
    "#             X_train_vectorized = vectorizer.transform(X_train['text'])\n",
    "#             X_test_vectorized = vectorizer.transform(X_test['text'])\n",
    "            \n",
    "#             y_pred = fit_predict(X_train_vectorized, y_train, X_test_vectorized)\n",
    "            \n",
    "#             print(f\"Cleaning type: {data_cleaning_type}, tokenizing type: {tokenizing_type}, vectorization_type: {vectorization_type}\")\n",
    "#             print(\"f1 score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_removed_all\n",
    "X = data[['text']].copy()\n",
    "y = data[['Class Index']].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text'] = X_train['text'].apply(lemmatizing)\n",
    "X_test['text'] = X_test['text'].apply(lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'vector_size': 100,\n",
    "            'window': 5,\n",
    "            'min_count': 1,\n",
    "            'workers': 4\n",
    "         }\n",
    "\n",
    "vectorizer = Vectorizer(\"word2vec\", params)\n",
    "\n",
    "vectorizer.fit(X_train['text'])\n",
    "            \n",
    "X_train_vectorized = vectorizer.transform(X_train['text'])\n",
    "X_test_vectorized = vectorizer.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46216666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = fit_predict(X_train_vectorized, y_train, X_test_vectorized)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X: np.array, y: np.array):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = np.array(y_train['Class Index']) - 1\n",
    "y_test_ = np.array(y_test['Class Index']) - 1\n",
    "\n",
    "train_dataset = NewsDataset(X_train_vectorized, y_train_)\n",
    "test_dataset = NewsDataset(X_test_vectorized, y_test_)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MLP\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            \n",
    "            batch_x, batch_y = batch_x.float(), batch_y.long()\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            \n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.float(), batch_y.float()\n",
    "            outputs = model(batch_x)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    # Вычисляем F1 Score\n",
    "    f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.3257\n",
      "Epoch [2/50], Loss: 1.2485\n",
      "Epoch [3/50], Loss: 1.2287\n",
      "Epoch [4/50], Loss: 1.2199\n",
      "Epoch [5/50], Loss: 1.2158\n",
      "Epoch [6/50], Loss: 1.2115\n",
      "Epoch [7/50], Loss: 1.2084\n",
      "Epoch [8/50], Loss: 1.2055\n",
      "Epoch [9/50], Loss: 1.2020\n",
      "Epoch [10/50], Loss: 1.1999\n",
      "Epoch [11/50], Loss: 1.1968\n",
      "Epoch [12/50], Loss: 1.1959\n",
      "Epoch [13/50], Loss: 1.1947\n",
      "Epoch [14/50], Loss: 1.1933\n",
      "Epoch [15/50], Loss: 1.1872\n",
      "Epoch [16/50], Loss: 1.1867\n",
      "Epoch [17/50], Loss: 1.1838\n",
      "Epoch [18/50], Loss: 1.1821\n",
      "Epoch [19/50], Loss: 1.1814\n",
      "Epoch [20/50], Loss: 1.1779\n",
      "Epoch [21/50], Loss: 1.1770\n",
      "Epoch [22/50], Loss: 1.1771\n",
      "Epoch [23/50], Loss: 1.1746\n",
      "Epoch [24/50], Loss: 1.1706\n",
      "Epoch [25/50], Loss: 1.1699\n",
      "Epoch [26/50], Loss: 1.1710\n",
      "Epoch [27/50], Loss: 1.1687\n",
      "Epoch [28/50], Loss: 1.1679\n",
      "Epoch [29/50], Loss: 1.1659\n",
      "Epoch [30/50], Loss: 1.1649\n",
      "Epoch [31/50], Loss: 1.1637\n",
      "Epoch [32/50], Loss: 1.1623\n",
      "Epoch [33/50], Loss: 1.1654\n",
      "Epoch [34/50], Loss: 1.1640\n",
      "Epoch [35/50], Loss: 1.1605\n",
      "Epoch [36/50], Loss: 1.1623\n",
      "Epoch [37/50], Loss: 1.1599\n",
      "Epoch [38/50], Loss: 1.1587\n",
      "Epoch [39/50], Loss: 1.1584\n",
      "Epoch [40/50], Loss: 1.1570\n",
      "Epoch [41/50], Loss: 1.1589\n",
      "Epoch [42/50], Loss: 1.1592\n",
      "Epoch [43/50], Loss: 1.1558\n",
      "Epoch [44/50], Loss: 1.1571\n",
      "Epoch [45/50], Loss: 1.1572\n",
      "Epoch [46/50], Loss: 1.1563\n",
      "Epoch [47/50], Loss: 1.1552\n",
      "Epoch [48/50], Loss: 1.1533\n",
      "Epoch [49/50], Loss: 1.1545\n",
      "Epoch [50/50], Loss: 1.1532\n",
      "F1 Score: 0.4903\n"
     ]
    }
   ],
   "source": [
    "input_dim = 100\n",
    "hidden_dim = 64\n",
    "output_dim = 4\n",
    "\n",
    "\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
    "f1 = evaluate(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
