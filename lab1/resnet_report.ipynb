{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from models.resnet import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"data/train_preproc.csv\").drop(columns=['Unnamed: 0'])\n",
    "y = pd.read_csv(\"data/y_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(X: pd.DataFrame, \n",
    "                        y: pd.DataFrame, \n",
    "                        test_size: float = 0.2, \n",
    "                        seed: int = 1, \n",
    "                        batch_size: int = 128):\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=seed,\n",
    "    )\n",
    "\n",
    "    X_train = torch.from_numpy(X_train.values.astype(np.float32)).float()\n",
    "    y_train = torch.from_numpy(y_train.values.astype(np.float32)).float().squeeze(-1)\n",
    "\n",
    "    X_val = torch.from_numpy(X_val.values.astype(np.float32)).float()\n",
    "    y_val = torch.from_numpy(y_val.values.astype(np.float32)).float().squeeze(-1)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=27)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=27)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X: pd.DataFrame, y: pd.DataFrame, params: dict = {}, seed: int = None):\n",
    "    train_loader, val_loader = prepare_dataloaders(X, y)\n",
    "\n",
    "    model = ResNet(X.shape[1], params)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "\n",
    "        callbacks=[\n",
    "            pl.callbacks.EarlyStopping(monitor='val_f1', mode='max', patience=15, min_delta=1e-4),\n",
    "            pl.callbacks.ModelCheckpoint(save_top_k=1, monitor=\"val_f1\", mode=\"max\"),\n",
    "        ],\n",
    "        accelerator=\"auto\",\n",
    "        enable_checkpointing=True,\n",
    "        logger=True\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict(model: torch.nn.Module, X_test: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    model.eval()\n",
    "    test_loader = DataLoader(torch.from_numpy(X_test.values.astype(np.float32)).float(),batch_size=2000)\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x in test_loader:\n",
    "            y_pred = model(x)\n",
    "            predictions.append(y_pred.cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(predictions)\n",
    "\n",
    "def compute_metric(labels, predicted_labels_proba, threshold=0.5):\n",
    "    predicted_labels = (predicted_labels_proba >= threshold).astype(np.int8)\n",
    "    return f1_score(labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_test(X, y, train_index, test_index, config = None) -> float:\n",
    "    X_train_ = X.loc[train_index,:]\n",
    "    X_test_ = X.loc[test_index,:]\n",
    "    y_train_ = y.loc[train_index, :]\n",
    "    y_test_ = y.loc[test_index, :]\n",
    "\n",
    "    model = fit(X_train_, y_train_, config)\n",
    "    pred_proba = predict(model, X_test_)\n",
    "    \n",
    "    return compute_metric(y_test_, pred_proba)\n",
    "\n",
    "def objective(trial):\n",
    "    config = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1,log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-2,log=True),\n",
    "        'n_hidden':trial.suggest_int('n_hidden', 2, 5),\n",
    "        'layer_size': trial.suggest_int('layer_size', 8, 512, log=True),\n",
    "        'batch_size': trial.suggest_int('batch_size', 32, 2048, log=True),\n",
    "        'normalization': trial.suggest_categorical('normalization', choices=['layer_norm']),#'batch_norm']),\n",
    "        'dropout': trial.suggest_categorical('dropout', choices=['dropout', 'dropout1d']),\n",
    "        'activation': trial.suggest_categorical('activation', choices=['relu', 'gelu']), \n",
    "        'use_scheduler': trial.suggest_categorical('use_scheduler', choices=['True', 'False']), \n",
    "        'hidden_factor': trial.suggest_float('hidden_factor', 1, 4),\n",
    "        'hidden_dropout': trial.suggest_float('hidden_dropout', 0, 0.5),\n",
    "        'residual_dropout': trial.suggest_float('residual_dropout', 0, 0.5),\n",
    "    }\n",
    "\n",
    "    X_train = pd.read_csv(\"data/train_preproc.csv\").drop(columns=['Unnamed: 0'])\n",
    "    y_train = pd.read_csv(\"data/y_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "    scores = []\n",
    "    for i,(train_index,test_index) in enumerate(cv.split(X_train, y_train)):\n",
    "\n",
    "        f1_score = fit_and_test(X_train, y_train, train_index, test_index, config)\n",
    "        scores.append(f1_score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(directions=['maximize'], study_name='mlp')\n",
    "study.optimize(objective, n_trials=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 0.006868056303589185, \n",
    "    'weight_decay': 6.898917214573194e-05, \n",
    "    'n_hidden': 4, \n",
    "    'layer_size': 14, \n",
    "    'batch_size': 234, \n",
    "    'normalization': 'layer_norm', \n",
    "    'dropout': 'dropout', \n",
    "    'activation': 'relu', \n",
    "    'use_scheduler': 'True', \n",
    "    'hidden_factor': 3.393384587761709, \n",
    "    'hidden_dropout': 0.05306977286016662, \n",
    "    'residual_dropout': 0.26162639347698424}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | loss       | BCELoss       | 0      | train\n",
      "1 | f1         | BinaryF1Score | 0      | train\n",
      "2 | activation | ReLU          | 0      | train\n",
      "3 | blocks     | Sequential    | 6.3 K  | train\n",
      "4 | prediction | Sequential    | 43     | train\n",
      "-----------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e753017237d4b02a1ba7246a028cb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = fit(X_train, y_train, best_params)\n",
    " \n",
    "predictions = predict(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = compute_metric(y_test, predictions)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ensemble = 5\n",
    "threshold = 0.5\n",
    "predictions_list = []\n",
    "\n",
    "X_y = X_train.join(y_train)\n",
    "\n",
    "for i in range(n_ensemble):\n",
    "    seed = n_ensemble * i\n",
    "    df_resampled = resample(X_y, replace=False, random_state=seed)\n",
    "\n",
    "    target = df_resampled[\"Grade\"]\n",
    "    train = df_resampled.drop(\"Grade\", axis=1)\n",
    "\n",
    "    model = fit(train, target, best_params, seed=seed)\n",
    "    pred_proba = predict(model, X_test)\n",
    "    \n",
    "    predictions_list.append(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.822429906542056"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction = np.mean(predictions_list, axis=0)\n",
    "predicted_labels = (final_prediction >= threshold).astype(np.int8)\n",
    "f1_score(y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m (predictions \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint8)\n\u001b[0;32m----> 2\u001b[0m confusion_m \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m(y_test, predicted_labels)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      5\u001b[0m ConfusionMatrixDisplay(confusion_m, display_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGG (0)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGBM (1)\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m, values_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_labels = (predictions >= 0.5).astype(np.int8)\n",
    "confusion_m = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay(confusion_m, display_labels=['LGG (0)', 'GBM (1)']).plot(cmap='Blues', values_format=\".0f\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"data/sample_submission_file.csv\")\n",
    "sub[\"Grade\"] = predicted_labels\n",
    "sub.to_csv(\"data/submission_file.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
